# NeuroTranslate

A supervised transformer to convert brain waves (EEG/fMRI) into video (what the person is seeing) and audio (what the person is hearing)

This is the main question we are trying to answer:

1. Provided some calibration, to what degree can we recreate what the person is seeing and listening?

## TODOs

1. [] Create a dataset of EEG/fMRI data and corresponding audio/video
2. [] Create a transformer model to convert EEG/fMRI into audio/video
3. [] Run experiments to evaluate the model

## Usage

TBD - but for now check `src/` for the code

## Dataset

TBD
